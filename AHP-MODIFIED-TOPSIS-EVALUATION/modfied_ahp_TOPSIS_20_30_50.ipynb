{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaisalAbid11/Permutation-Entropy-vs-Modified-TOPSIS/blob/main/AHP-MODIFIED-TOPSIS-EVALUATION/modfied_ahp_TOPSIS_20_30_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1.First we imported all the necessary libraries and packages.\n",
        "2.Then we uploaded the datasets (Distressed).\n",
        "3.Then we balanced the dataset using SMOTE.\n",
        "4.Then We splitted the dataset in 70:30 (train:test) ratio\n",
        "5.Then we normalized the data.\n",
        "6.Then we defined and tuned our classifier model, used parameters suitbale for goof performances.\n",
        "7.Then we found optimized threshhold for each model.\n",
        "8.Then we evaluated the models and printed the results\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.over_sampling import SMOTE,BorderlineSMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "\n",
        "#Upload and balance Dataset\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/FaisalAbid11/Permutation-Entropy-vs-Modified-TOPSIS/refs/heads/main/AHP-MODIFIED-TOPSIS-EVALUATION/distressed.csv\") # load distressed file\n",
        "X = data.drop('TOI', axis=1)\n",
        "y = data['TOI']\n",
        "smote = SMOTE(sampling_strategy=0.6, random_state=42,k_neighbors=1)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "data_balanced = pd.DataFrame(X, columns=X.columns)\n",
        "data_balanced['TOI'] = y\n",
        "data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Normalized the datasets\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Defined classifier models\n",
        "svm = SVC(C=1, kernel='rbf', probability=True, class_weight='balanced',random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=11, weights='distance', metric='euclidean')\n",
        "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42,max_depth=10,max_features='sqrt')\n",
        "xgb = XGBClassifier(n_estimators=500, eval_metric='logloss',scale_pos_weight=2, random_state=42,max_depth=15, colsample_bytree=1,subsample=0.5)\n",
        "\n",
        "#Trained the models\n",
        "models = {'SVM': svm, 'KNN': knn,'Random Forest': rf, 'XGBoost': xgb} # run SVM, KNN, Random forest , XGboost\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_probs = {name: model.predict_proba(X_test)[:, 1] for name, model in models.items()}\n",
        "\n",
        "#Finding Optimized Threshhold\n",
        "def optimize_threshold(y_true, y_prob):\n",
        "    best_mcc, best_thresh = -1, 0.5\n",
        "    for thresh in np.linspace(0.1, 0.9, 200):\n",
        "        y_pred_adjusted = (y_prob >= thresh).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true, y_pred_adjusted)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc, best_thresh = mcc, thresh\n",
        "    return best_thresh\n",
        "\n",
        "thresholds = {name: optimize_threshold(y_test, y_pred_probs[name]) for name in models}\n",
        "\n",
        "#Test\n",
        "y_preds = {name: (y_pred_probs[name] >= thresholds[name]).astype(int) for name in models}\n",
        "\n",
        "\n",
        "\n",
        "#Evaluate and Print\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"MCC:\", matthews_corrcoef(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_prob))\n",
        "    print(\"G-Mean:\", geometric_mean_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "for name in models:\n",
        "    evaluate_model(name, y_test, y_preds[name], y_pred_probs[name])\n",
        "\n",
        "\n",
        "# logistic regression\n",
        "X= data.drop('TOI', axis=1)\n",
        "y = data['TOI']\n",
        "\n",
        "smote =SMOTE(sampling_strategy='auto', random_state=42,k_neighbors=1)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "data_balanced = pd.DataFrame(X, columns=X.columns)\n",
        "data_balanced['TOI'] = y\n",
        "data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, C=0.1, solver='newton-cg',penalty='l2',class_weight={0:1,1:1}) # logistic regression function\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr_prob = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "def optimize_threshold(y_true, y_prob):\n",
        "    best_mcc, best_thresh = -1, 0.5\n",
        "    for thresh in np.linspace(0.1, 0.9, 200):\n",
        "        y_pred_adjusted = (y_prob >= thresh).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true, y_pred_adjusted)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc, best_thresh = mcc, thresh\n",
        "    return best_thresh\n",
        "\n",
        "\n",
        "lr_thresh = optimize_threshold(y_test, y_pred_lr_prob)\n",
        "y_pred_lr = (y_pred_lr_prob >= lr_thresh).astype(int)\n",
        "\n",
        "#Evaluate and Print\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"MCC:\", matthews_corrcoef(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_prob))\n",
        "    print(\"G-Mean:\", geometric_mean_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", y_test, y_pred_lr, y_pred_lr_prob)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH6RtCk1T05i",
        "outputId": "fe680a14-4535-4a2c-fab4-b27d5fd8c909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Metrics:\n",
            "Accuracy: 0.9361702127659575\n",
            "Precision: 0.9378006032444771\n",
            "Recall: 0.9361702127659575\n",
            "F1 Score: 0.9365411364690125\n",
            "MCC: 0.8643995242075444\n",
            "AUC-ROC: 0.9637254901960784\n",
            "G-Mean: 0.9372466978064098\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91        17\n",
            "           1       0.97      0.93      0.95        30\n",
            "\n",
            "    accuracy                           0.94        47\n",
            "   macro avg       0.93      0.94      0.93        47\n",
            "weighted avg       0.94      0.94      0.94        47\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[16  1]\n",
            " [ 2 28]]\n",
            "\n",
            "KNN Metrics:\n",
            "Accuracy: 0.9148936170212766\n",
            "Precision: 0.9311043566362714\n",
            "Recall: 0.9148936170212766\n",
            "F1 Score: 0.9163333866581348\n",
            "MCC: 0.8376080835255243\n",
            "AUC-ROC: 0.9666666666666667\n",
            "G-Mean: 0.9309493362512627\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.89        17\n",
            "           1       1.00      0.87      0.93        30\n",
            "\n",
            "    accuracy                           0.91        47\n",
            "   macro avg       0.90      0.93      0.91        47\n",
            "weighted avg       0.93      0.91      0.92        47\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[17  0]\n",
            " [ 4 26]]\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.9574468085106383\n",
            "Precision: 0.961926091825308\n",
            "Recall: 0.9574468085106383\n",
            "F1 Score: 0.9578951658922312\n",
            "MCC: 0.913831340728827\n",
            "AUC-ROC: 0.9715686274509804\n",
            "G-Mean: 0.9660917830792959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        17\n",
            "           1       1.00      0.93      0.97        30\n",
            "\n",
            "    accuracy                           0.96        47\n",
            "   macro avg       0.95      0.97      0.95        47\n",
            "weighted avg       0.96      0.96      0.96        47\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[17  0]\n",
            " [ 2 28]]\n",
            "\n",
            "XGBoost Metrics:\n",
            "Accuracy: 0.9574468085106383\n",
            "Precision: 0.9574468085106383\n",
            "Recall: 0.9574468085106383\n",
            "F1 Score: 0.9574468085106383\n",
            "MCC: 0.907843137254902\n",
            "AUC-ROC: 0.9362745098039216\n",
            "G-Mean: 0.9538364228569947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        17\n",
            "           1       0.97      0.97      0.97        30\n",
            "\n",
            "    accuracy                           0.96        47\n",
            "   macro avg       0.95      0.95      0.95        47\n",
            "weighted avg       0.96      0.96      0.96        47\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[16  1]\n",
            " [ 1 29]]\n",
            "\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.8983050847457628\n",
            "Precision: 0.9000313873195228\n",
            "Recall: 0.8983050847457628\n",
            "F1 Score: 0.8981293446848396\n",
            "MCC: 0.7981593341498341\n",
            "AUC-ROC: 0.9362068965517243\n",
            "G-Mean: 0.8969937018449045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90        30\n",
            "           1       0.93      0.86      0.89        29\n",
            "\n",
            "    accuracy                           0.90        59\n",
            "   macro avg       0.90      0.90      0.90        59\n",
            "weighted avg       0.90      0.90      0.90        59\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[28  2]\n",
            " [ 4 25]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "1.First we imported all the necessary libraries and packages.\n",
        "2.Then we uploaded the datasets (Behavioral).\n",
        "3.Then we balanced the dataset using BorderlineSMOTE.\n",
        "4.Then We splitted the dataset in 70:30 (train:test) ratio\n",
        "5.Then we normalized the data.\n",
        "6.Then we defined and tuned our classifier model, used parameters suitbale for goof performances.\n",
        "7.Then we found optimized threshhold for each model.\n",
        "8.Then we evaluated the models and printed the results\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.over_sampling import SMOTE,BorderlineSMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "#Upload and balance the dataset\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/FaisalAbid11/Permutation-Entropy-vs-Modified-TOPSIS/refs/heads/main/AHP-MODIFIED-TOPSIS-EVALUATION/behavioral.csv\") # load behavioral file\n",
        "X = data.drop('TOI', axis=1)\n",
        "y = data['TOI']\n",
        "\n",
        "smote = BorderlineSMOTE(sampling_strategy=0.8, random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "data_balanced = pd.DataFrame(X, columns=X.columns)\n",
        "data_balanced['TOI'] = y\n",
        "data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Normalized the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Define the models\n",
        "svm = SVC(C=1, kernel='rbf', probability=True, class_weight='balanced',random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', metric='manhattan')\n",
        "rf = RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=42,max_depth=10,max_features='sqrt')\n",
        "xgb = XGBClassifier(n_estimators=500, eval_metric='logloss',scale_pos_weight=3, random_state=42,max_depth=10, colsample_bytree=1,subsample=0.5,gamma=0.5)\n",
        "\n",
        "#Train\n",
        "models = {'SVM': svm, 'KNN': knn,'Random Forest': rf, 'XGBoost': xgb}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_probs = {name: model.predict_proba(X_test)[:, 1] for name, model in models.items()}\n",
        "\n",
        "\n",
        "#Finding Optimized Threshold\n",
        "def optimize_threshold(y_true, y_prob):\n",
        "    best_mcc, best_thresh = -1, 0.5\n",
        "    for thresh in np.linspace(0.1, 0.9, 200):\n",
        "        y_pred_adjusted = (y_prob >= thresh).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true, y_pred_adjusted)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc, best_thresh = mcc, thresh\n",
        "    return best_thresh\n",
        "\n",
        "thresholds = {name: optimize_threshold(y_test, y_pred_probs[name]) for name in models}\n",
        "\n",
        "#Test\n",
        "y_preds = {name: (y_pred_probs[name] >= thresholds[name]).astype(int) for name in models}\n",
        "\n",
        "#Evauate And print\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"MCC:\", matthews_corrcoef(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_prob))\n",
        "    print(\"G-Mean:\", geometric_mean_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "for name in models:\n",
        "    evaluate_model(name, y_test, y_preds[name], y_pred_probs[name])\n",
        "\n",
        "\n",
        "#For Logistic regression\n",
        "X = data.drop('TOI', axis=1)\n",
        "y = data['TOI']\n",
        "\n",
        "smote = BorderlineSMOTE(sampling_strategy=1, random_state=42,k_neighbors=1)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000,solver='liblinear',C=1,penalty='l1',random_state=42) # logistic regression\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr_prob = lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "def optimize_threshold(y_true, y_prob):\n",
        "    best_mcc, best_thresh = -1, 0.5\n",
        "    for thresh in np.linspace(0.1, 0.9, 100):\n",
        "        y_pred_adjusted = (y_prob >= thresh).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true, y_pred_adjusted)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc, best_thresh = mcc, thresh\n",
        "    return best_thresh\n",
        "\n",
        "lr_thresh = optimize_threshold(y_test, y_pred_lr_prob)\n",
        "\n",
        "\n",
        "\n",
        "y_pred_lr = (y_pred_lr_prob >= lr_thresh).astype(int)\n",
        "\n",
        "#Evaluate and Print\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"MCC:\", matthews_corrcoef(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_prob))\n",
        "    print(\"G-Mean:\", geometric_mean_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "evaluate_model(\"Logistic Regression\", y_test, y_pred_lr, y_pred_lr_prob)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBLtKPTXVBfz",
        "outputId": "7deba6db-b770-4303-cbb8-0d6b2e0a5ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Metrics:\n",
            "Accuracy: 0.9305555555555556\n",
            "Precision: 0.9379432624113476\n",
            "Recall: 0.9305555555555556\n",
            "F1 Score: 0.9293496765406878\n",
            "MCC: 0.8629489272626913\n",
            "AUC-ROC: 0.942857142857143\n",
            "G-Mean: 0.9128709291752769\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        42\n",
            "           1       1.00      0.83      0.91        30\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.95      0.92      0.93        72\n",
            "weighted avg       0.94      0.93      0.93        72\n",
            "\n",
            "\n",
            "KNN Metrics:\n",
            "Accuracy: 0.9305555555555556\n",
            "Precision: 0.932716049382716\n",
            "Recall: 0.9305555555555556\n",
            "F1 Score: 0.9299253881831014\n",
            "MCC: 0.8583237015949035\n",
            "AUC-ROC: 0.9416666666666667\n",
            "G-Mean: 0.9197998401998916\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        42\n",
            "           1       0.96      0.87      0.91        30\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.94      0.92      0.93        72\n",
            "weighted avg       0.93      0.93      0.93        72\n",
            "\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.9583333333333334\n",
            "Precision: 0.9611111111111111\n",
            "Recall: 0.9583333333333334\n",
            "F1 Score: 0.9579552329098608\n",
            "MCC: 0.9165151389911681\n",
            "AUC-ROC: 0.9547619047619048\n",
            "G-Mean: 0.9486832980505138\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.97        42\n",
            "           1       1.00      0.90      0.95        30\n",
            "\n",
            "    accuracy                           0.96        72\n",
            "   macro avg       0.97      0.95      0.96        72\n",
            "weighted avg       0.96      0.96      0.96        72\n",
            "\n",
            "\n",
            "XGBoost Metrics:\n",
            "Accuracy: 0.9305555555555556\n",
            "Precision: 0.9305666933974872\n",
            "Recall: 0.9305555555555556\n",
            "F1 Score: 0.9303755400465271\n",
            "MCC: 0.85681247690209\n",
            "AUC-ROC: 0.9484126984126984\n",
            "G-Mean: 0.9258200997725514\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        42\n",
            "           1       0.93      0.90      0.92        30\n",
            "\n",
            "    accuracy                           0.93        72\n",
            "   macro avg       0.93      0.93      0.93        72\n",
            "weighted avg       0.93      0.93      0.93        72\n",
            "\n",
            "\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.875\n",
            "Precision: 0.890625\n",
            "Recall: 0.875\n",
            "F1 Score: 0.8737373737373737\n",
            "MCC: 0.7654655446197431\n",
            "AUC-ROC: 0.88375\n",
            "G-Mean: 0.8692669325356855\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.78      0.86        40\n",
            "           1       0.81      0.97      0.89        40\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.89      0.88      0.87        80\n",
            "weighted avg       0.89      0.88      0.87        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "1.First we imported all the necessary libraries and packages.\n",
        "2.Then we uploaded the datasets (Enthusiastic).\n",
        "3.Then we balanced the dataset using SMOTE.\n",
        "4.Then We splitted the dataset in 70:30 (train:test) ratio\n",
        "5.Then we normalized the data.\n",
        "6.Then we defined and tuned our classifier model, used parameters suitbale for goof performances.\n",
        "7.Then we found optimized threshhold for each model.\n",
        "8.Then we evaluated the models and printed the results\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.over_sampling import SMOTE,BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "#Upload and Balance the Dataset\n",
        "file_path = 'https://raw.githubusercontent.com/FaisalAbid11/Permutation-Entropy-vs-Modified-TOPSIS/refs/heads/main/AHP-MODIFIED-TOPSIS-EVALUATION/enthusiastic.csv' # load enthusiastic dataset\n",
        "data = pd.read_csv(file_path)\n",
        "X = data.drop('TOI', axis=1)\n",
        "y = data['TOI']\n",
        "\n",
        "smote =SMOTE(sampling_strategy=0.8,random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "data_balanced = pd.DataFrame(X, columns=X.columns)\n",
        "data_balanced['TOI'] = y\n",
        "data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Normalie Data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Define Models\n",
        "svm = SVC(C=1, kernel='rbf', probability=True, class_weight={0:0.75,1:1.5},random_state=42)\n",
        "knn = KNeighborsClassifier(n_neighbors=11, weights='distance', metric='euclidean')\n",
        "rf = RandomForestClassifier(n_estimators=1000, class_weight={0:1,1:1}, random_state=42,max_depth=20,criterion='entropy')\n",
        "xgb = XGBClassifier(eval_metric='logloss',scale_pos_weight=5, random_state=42,subsample=0.5)\n",
        "lr =  LogisticRegression(C=0.001, class_weight={0:0.25,1:3},solver='lbfgs', max_iter=1000,random_state=42)\n",
        "\n",
        "\n",
        "#Train\n",
        "models = {'SVM': svm, 'KNN': knn,'Random Forest': rf, 'XGBoost': xgb, 'Logistic Regression':lr} # run the classifier models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_probs = {name: model.predict_proba(X_test)[:, 1] for name, model in models.items()}\n",
        "\n",
        "#Finding optimized threshold\n",
        "\n",
        "def optimize_threshold(y_true, y_prob):\n",
        "    best_mcc, best_thresh = -1, 0.5\n",
        "    for thresh in np.arange(0.1, 0.9, 0.005):\n",
        "        y_pred_adjusted = (y_prob >= thresh).astype(int)\n",
        "        mcc = matthews_corrcoef(y_true, y_pred_adjusted)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc, best_thresh = mcc, thresh\n",
        "    return best_thresh\n",
        "\n",
        "\n",
        "thresholds = {name: optimize_threshold(y_test, y_pred_probs[name]) for name in models}\n",
        "\n",
        "#Test\n",
        "y_preds = {name: (y_pred_probs[name] >= thresholds[name]).astype(int) for name in models}\n",
        "\n",
        "#Evaluate and print\n",
        "def evaluate_model(name, y_true, y_pred, y_prob):\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"MCC:\", matthews_corrcoef(y_true, y_pred))\n",
        "    print(\"AUC-ROC:\", roc_auc_score(y_true, y_prob))\n",
        "    print(\"G-Mean:\", geometric_mean_score(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "for name in models:\n",
        "    evaluate_model(name, y_test, y_preds[name], y_pred_probs[name])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGh5kljvUY9M",
        "outputId": "52395dc4-84a2-4d41-8c70-4bdffae357b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Metrics:\n",
            "Accuracy: 0.9259259259259259\n",
            "Precision: 0.9343116701607268\n",
            "Recall: 0.9259259259259259\n",
            "F1 Score: 0.9245639187574671\n",
            "MCC: 0.8545757234070167\n",
            "AUC-ROC: 0.9655819774718398\n",
            "G-Mean: 0.9074852129730301\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        47\n",
            "           1       1.00      0.82      0.90        34\n",
            "\n",
            "    accuracy                           0.93        81\n",
            "   macro avg       0.94      0.91      0.92        81\n",
            "weighted avg       0.93      0.93      0.92        81\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[47  0]\n",
            " [ 6 28]]\n",
            "\n",
            "KNN Metrics:\n",
            "Accuracy: 0.9135802469135802\n",
            "Precision: 0.9247828074988569\n",
            "Recall: 0.9135802469135802\n",
            "F1 Score: 0.9116164804094253\n",
            "MCC: 0.8313702367707394\n",
            "AUC-ROC: 0.9580725907384231\n",
            "G-Mean: 0.8911327886790068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93        47\n",
            "           1       1.00      0.79      0.89        34\n",
            "\n",
            "    accuracy                           0.91        81\n",
            "   macro avg       0.94      0.90      0.91        81\n",
            "weighted avg       0.92      0.91      0.91        81\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[47  0]\n",
            " [ 7 27]]\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.9382716049382716\n",
            "Precision: 0.9442070275403608\n",
            "Recall: 0.9382716049382716\n",
            "F1 Score: 0.9373808633067893\n",
            "MCC: 0.8780248298368074\n",
            "AUC-ROC: 0.9680851063829787\n",
            "G-Mean: 0.9235481451827989\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95        47\n",
            "           1       1.00      0.85      0.92        34\n",
            "\n",
            "    accuracy                           0.94        81\n",
            "   macro avg       0.95      0.93      0.94        81\n",
            "weighted avg       0.94      0.94      0.94        81\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[47  0]\n",
            " [ 5 29]]\n",
            "\n",
            "XGBoost Metrics:\n",
            "Accuracy: 0.9382716049382716\n",
            "Precision: 0.9400398247710077\n",
            "Recall: 0.9382716049382716\n",
            "F1 Score: 0.9378016663240031\n",
            "MCC: 0.8743074868105586\n",
            "AUC-ROC: 0.9518147684605758\n",
            "G-Mean: 0.9292897687712529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95        47\n",
            "           1       0.97      0.88      0.92        34\n",
            "\n",
            "    accuracy                           0.94        81\n",
            "   macro avg       0.94      0.93      0.94        81\n",
            "weighted avg       0.94      0.94      0.94        81\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[46  1]\n",
            " [ 4 30]]\n",
            "\n",
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.9135802469135802\n",
            "Precision: 0.9134867190422745\n",
            "Recall: 0.9135802469135802\n",
            "F1 Score: 0.9133901641888026\n",
            "MCC: 0.8221324074022045\n",
            "AUC-ROC: 0.9217772215269086\n",
            "G-Mean: 0.9088633234297909\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93        47\n",
            "           1       0.91      0.88      0.90        34\n",
            "\n",
            "    accuracy                           0.91        81\n",
            "   macro avg       0.91      0.91      0.91        81\n",
            "weighted avg       0.91      0.91      0.91        81\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[44  3]\n",
            " [ 4 30]]\n"
          ]
        }
      ]
    }
  ]
}